1。解释回归问题的常用loss:
http://baijiahao.baidu.com/s?id=1603857666277651546&wfr=spider&for=pc
重点：Huber损失，它会由于梯度的减小而落在最小值附近。
比起MSE，它对异常点更加鲁棒。因此，Huber损失结合了MSE和MAE的优点。
但是，Huber损失的问题是我们可能需要不断调整超参数delta。

2。回归模型正是表示从输入变量到输出变量之间映射的函数。回归问题的学习等价于函数拟合：选择一条函数曲线，使其很好地拟合已知数据且很好地预测未知数据。
回归问题按照输入变量的个数，可以分为一元回归和多元回归；按照输入变量与输出变量之间关系的类型，可以分为线性回归和非线性回归。
回归学习最常用的损失函数是平方损失，在此情况下，回归问题可以由著名的最小二乘法求解。
